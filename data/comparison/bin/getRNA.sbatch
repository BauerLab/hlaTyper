#!/bin/sh -e

#SBATCH --time=10:00:00
#SBATCH --mem=16gb
#SBATCH --job-name=download
#SBATCH --out out/1000GExtrDownloadRNA/download_%A_%a.out
echo $SLURM_JOBID

module load samtools/1.3
module load bedtools

. ./config.txt

DIRDERIVED=/home/d/1000genomes/RNAseq
OUTDIR=fastq/1000RExtrChr6
REGIONS="chr"$(cat supportingData/hlaLocsChr6.txt | gawk '{ ORS=" "; print; }')
echo $REGIONS

# grep "Giving up." out/1000GExtrDownloadRNA/download_71016_* -l | cut -f 3 -d "_" | sed 's/.out//g' | gawk 'ORS="," {print $0}'
# sbatch -a 115,118,119,120,1215,1216,1217,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,124,1250,1251,1252,1253,1255,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1302,1304,132,133,136,137,140,142,143,144,146,147,149,152,155,156,157,159,161,162,163,164,166,168,169,172,173,174,177,178,179,180,185,187,189,190,191,193,194,392,446,447,450,460,462,463,465,468,469,472,486,488,501,502,503,504,506,507,508,511,512,513,515,517,518,519,520,521,522,523,525,526,527,528,529,530,534,537,540,541,542,543,547,549,550,552,553,554,555,556,558,559,561,562,565,566,567,568,571,572,573,574,577,578,579,667,670,673,676,785,788,791,794,897,898,900,901,904,906,907,911,912,913,915,916,919,921,922,924,925,928,930,931,936,937,942,943,945,946,949,950 bin/getRNA.sbatch
# new 72399
# sbatch -a 1217,1219,1220,1221,1222,1223,1224,1226,1227,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1255,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1302,1304,133,136,142,143,144,149,152,155,157,162,164,166,169,172,174,177,179,185,187,189,190,191,193,194,392,446,447,450,460,463,468,469,486,488,501,504,508,511,513,515,517,518,519,521,523,526,527,528,529,530,534,537,540,543,547,549,550,552,553,554,555,558,559,561,566,567,568,571,572,573,574,577,667,670,673,785,788,791,897,898,900,901,904,906,907,912,913,916,919,924,925,930,931,93 bin/getRNA.sbatch
# new 72751
# sbatch -a 1217,1219,1220,1221,1222,1223,1224,1226,1227,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1255,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1302,1304,133,136,142,143,144,149,152,155,157,162,164,166,169,172,174,177,179,185,187,189,190,191,193,194,392,446,447,450,460,463,468,469,486,488,501,504,508,511,513,515,517,518,519,521,523,526,527,528,529,530,534,537,540,543,547,549,550,552,553,554,555,558,559,561,566,567,568,571,572,573,574,577,667,670,673,785,788,791,897,898,900,901,904,906,907,912,913,916,919,924,925,930,931,93 bin/getRNA.sbatch
# limit to 10 simulteneous connections
# new 72986
#sbatch --array=1220,1221,1234,1235,1236,1237,1238,1239,1240,1242,1243,1244,1247,1253,1255,1260,1268,1270,1271,1273,1274,1275,1276,1278,1283,1286,1289,1291,1293,1295,1296,1297,1298,1299,1300,1302,1304,143,162,172,179,185,187,189,194,468,501,504,508,511,519,527,529,534,540,553,555,559,561,568,572,573,670,673,897,898,907,916,930,931%10 bin/getRNA.sbatch
# sbatch --array=1-1304%10 bin/getRNA.sbatch
#sbatch --array=115 bin/getRNA.sbatch
#for i in $(grep FINISHED out/1000GExtrDownloadRNA/download_75102_* -L ); do grep "missing URL" $i -L ; done

##SLURM_ARRAY_TASK_ID=1

SAMPLE=$(head -n ${SLURM_ARRAY_TASK_ID} iter/goldstandard1KG.txt | tail -1)
#SAMPLE=${id/*_/}
#SAMPLE=${SAMPLE/.*/}
echo $SAMPLE

URL=$(grep $SAMPLE /home/d/1000genomes/E-GEUV-1.sdrf.txt | cut -f 32 | head -n 1)
URL=${URL/E-GEUV-1/E-GEUV-1\/processed}

if [[ ! -e $DIRDERIVED/$SAMPLE.bam || ! -s $DIRDERIVED/$SAMPLE.bam || ! -e $DIRDERIVED/$SAMPLE.bam.bai || ! -s $DIRDERIVED/$SAMPLE.bam.bai ]]; then
    echo "download bam"
    echo $URL
    wget $URL -O $DIRDERIVED/$SAMPLE.bam
    echo "download bai"
    echo $URL.bai
    wget $URL.bai -O $DIRDERIVED/$SAMPLE.bam.bai
fi

TMP=/flush1/bau04c/HLA/download/$RANDOM/
mkdir -p $TMP

if [[ ! -e $DIRDERIVED/$SAMPLE.bam.cov  || ! -s $DIRDERIVED/$SAMPLE.bam.cov ]]; then
    echo "get coverage"
    samtools sort -O bam -T $TMP $DIRDERIVED/$SAMPLE.bam | samtools depth - |  awk '{sum+=$3; sumsq+=$3*$3} END { print "Average = ",sum/NR; print "Stdev = ",sqrt(sumsq/NR - (sum/NR)**2)}' >$DIRDERIVED/$SAMPLE.bam.cov
fi

#ls $DIRDERIVED/$SAMPLE.bam
#samtools view -f 1 -b $DIRDERIVED/$SAMPLE.bam $REGIONS | samtools rmdup - - | \
#  samtools sort -T $TMP -n > $TMP/${SAMPLE}.srt.bam
if [[ ! -e $OUTDIR/${SAMPLE}_${READ1NAME}.fastq.gz  || ! -s $OUTDIR/${SAMPLE}_${READ1NAME}.fastq.gz ]]; then
  echo "extract read"
  samtools view -f 1 -b $DIRDERIVED/$SAMPLE.bam $REGIONS '*' | \
    samtools sort -T $TMP -n > $TMP/${SAMPLE}.srt.bam

  echo "stats"
  samtools flagstat $TMP/${SAMPLE}.srt.bam > $OUTDIR/${SAMPLE}.stats
  samtools sort -O bam -T $TMP $TMP/${SAMPLE}.srt.bam | samtools depth - |  awk '{sum+=$3; sumsq+=$3*$3} END { print "Average = ",sum/NR; print "Stdev = ",sqrt(sumsq/NR - (sum/NR)**2)}' >$OUTDIR/${SAMPLE}.bam.cov

  echo "make fastq"
  bedtools bamtofastq -i $TMP/${SAMPLE}.srt.bam \
                        -fq $TMP/${SAMPLE}_${READ1NAME}.fastq \
                        -fq2 $TMP/${SAMPLE}_${READ2NAME}.fastq 2> /dev/null


  echo "zip"
  gzip $TMP/${SAMPLE}_${READ1NAME}.fastq
  gzip $TMP/${SAMPLE}_${READ2NAME}.fastq
  mv $TMP/${SAMPLE}*.gz $OUTDIR/
fi

rm -r $TMP

echo "FINISHED"
